{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "import torch\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import wordnet as wn\n",
    "import traceback\n",
    "import pke\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from flashtext import KeywordProcessor\n",
    "import streamlit as st\n",
    "% % writefile app.py\n",
    "# !pip install --quiet git+https://github.com/boudinfl/pke.git@dc4d5f21e0ffe64c4df93c46146d29d1c522476b\n",
    "# !pip install --quiet flashtext==2.7\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('brown')\n",
    "nltk.download('wordnet')\n",
    "# !pip install --quiet transformers==4.5.0\n",
    "# !pip install --quiet sentencepiece==0.1.95\n",
    "# !pip install --quiet textwrap3==0.9.2\n",
    "# !pip install --quiet nltk==3.2.5\n",
    "\n",
    "st.title(\"Question Generation Bot\")\n",
    "st.subheader(\"Get practice questions for any piece of text that you're studying. Ex. A paragraph on Napoleon from your History textbook.\")\n",
    "\n",
    "st.markdown('#')\n",
    "\n",
    "\n",
    "def postprocesstext(content):\n",
    "  final = \"\"\n",
    "  for sent in sent_tokenize(content):\n",
    "    sent = sent.capitalize()\n",
    "    final = final + \" \"+sent\n",
    "  return final\n",
    "\n",
    "\n",
    "def summarizer(text, model, tokenizer, device):\n",
    "  text = text.strip().replace(\"\\n\", \" \")\n",
    "  text = \"summarize: \"+text\n",
    "  max_len = 512\n",
    "  encoding = tokenizer.encode_plus(\n",
    "      text, max_length=max_len, pad_to_max_length=False, truncation=True, return_tensors=\"pt\").to(device)\n",
    "\n",
    "  input_ids, attention_mask = encoding[\"input_ids\"], encoding[\"attention_mask\"]\n",
    "\n",
    "  outputs = model.generate(input_ids=input_ids,\n",
    "                           attention_mask=attention_mask,\n",
    "                           early_stopping=True,\n",
    "                           num_beams=3,\n",
    "                           num_return_sequences=1,\n",
    "                           no_repeat_ngram_size=2,\n",
    "                           min_length=75,\n",
    "                           max_length=300)\n",
    "\n",
    "  dec = [tokenizer.decode(ids, skip_special_tokens=True) for ids in outputs]\n",
    "  summary = dec[0]\n",
    "  summary = postprocesstext(summary)\n",
    "  summary = summary.strip()\n",
    "\n",
    "  return summary\n",
    "\n",
    "\n",
    "def get_nouns_multipartite(content):\n",
    "  output = []\n",
    "  try:\n",
    "    extractor = pke.unsupervised.MultipartiteRank()\n",
    "    extractor.load_document(input=content)\n",
    "\n",
    "    pos = {'PRRPN', 'NOUN'}\n",
    "    stoplist = list(string.punctuation)\n",
    "    stoplist += ['-lrb-', '-rrb-', '-lcb-', '-rcb-', '-lsb-', '-rsb-']\n",
    "    stoplist += stopwords.words('english')\n",
    "    extractor.candidate_selection(pos=pos, stoplist=stoplist)\n",
    "\n",
    "    extractor.candidate_weighting(alpha=1.1,\n",
    "                                  threshold=0.75,\n",
    "                                  method='average')\n",
    "    keyphrases = extractor.get_n_best(n=15)\n",
    "\n",
    "    for val in keyphrases:\n",
    "      output.append(val[0])\n",
    "  except:\n",
    "    output = []\n",
    "    traceback.print_exc()\n",
    "\n",
    "  return output\n",
    "\n",
    "\n",
    "def get_keywords(originaltext, summarytext):\n",
    "  keywords = get_nouns_multipartite(originaltext)\n",
    "\n",
    "  print(\"keywords unsummarized: \", keywords)\n",
    "  keyword_processor = KeywordProcessor()\n",
    "  for keyword in keywords:\n",
    "    keyword_processor.add_keyword(keyword)\n",
    "\n",
    "  keywords_found = keyword_processor.extract_keywords(summarytext)\n",
    "  keywords_found = list(set(keywords_found))\n",
    "  print(\"keywords_found in summarized: \", keywords_found)\n",
    "\n",
    "  important_keywords = []\n",
    "  for keyword in keywords:\n",
    "    if keyword in keywords_found:\n",
    "      important_keywords.append(keyword)\n",
    "\n",
    "  return important_keywords[:5]\n",
    "\n",
    "\n",
    "def get_question(context, answer, model, tokenizer):\n",
    "  text = \"context: {} answer: {}\".format(context, answer)\n",
    "  encoding = tokenizer.encode_plus(\n",
    "      text, max_length=384, pad_to_max_length=False, truncation=True, return_tensors=\"pt\").to(device)\n",
    "  input_ids, attention_mask = encoding[\"input_ids\"], encoding[\"attention_mask\"]\n",
    "\n",
    "  outs = model.generate(input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        early_stopping=True,\n",
    "                        num_beams=5,\n",
    "                        num_return_sequences=1,\n",
    "                        no_repeat_ngram_size=2,\n",
    "                        max_length=72)\n",
    "\n",
    "  dec = [tokenizer.decode(ids, skip_special_tokens=True) for ids in outs]\n",
    "\n",
    "  Question = dec[0].replace(\"question:\", \"\")\n",
    "  Question = Question.strip()\n",
    "  return Question\n",
    "\n",
    "\n",
    "@st.cache(allow_output_mutation=True)\n",
    "def load_model():\n",
    "  summary_model = T5ForConditionalGeneration.from_pretrained('t5-base')\n",
    "  summary_tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "  summary_model = summary_model.to(device)\n",
    "\n",
    "  question_model = T5ForConditionalGeneration.from_pretrained(\n",
    "      'ramsrigouthamg/t5_squad_v1')\n",
    "  question_tokenizer = T5Tokenizer.from_pretrained(\n",
    "      'ramsrigouthamg/t5_squad_v1')\n",
    "  device2 = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "  question_model = question_model.to(device2)\n",
    "\n",
    "  return summary_model, question_model, summary_tokenizer, question_tokenizer\n",
    "\n",
    "\n",
    "with st.spinner('Loading Model'):\n",
    "  summary_model, question_model, summary_tokenizer, question_tokenizer = load_model()\n",
    "\n",
    "\n",
    "text = st.text_area(\"Enter text below.\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if text:\n",
    "  st.write('Questions:')\n",
    "\n",
    "  with st.spinner('Generating....'):\n",
    "    summarized_text = summarizer(\n",
    "        text, summary_model, summary_tokenizer, device)\n",
    "    imp_keywords = get_keywords(text, summarized_text)\n",
    "\n",
    "    st.write(imp_keywords)\n",
    "\n",
    "    questions = {}\n",
    "    for answer in imp_keywords:\n",
    "      ques = get_question(summarized_text, answer,\n",
    "                          question_model, question_tokenizer)\n",
    "      questions[ques] = answer\n",
    "\n",
    "    st.write(questions)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
